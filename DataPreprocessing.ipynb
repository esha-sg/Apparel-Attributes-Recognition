{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook contains code to prepare dataset for training to recognise apparel attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing tensorflow and numpy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initializing the imagenet directory and training images directory\n",
    "model_dir = \"imagenet\"\n",
    "attribute_training_images = \"ClothingAttributeDataset/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the list of training images names\n",
    "training_images = [attribute_training_images+f for f in os.listdir(attribute_training_images) if re.search('jpg|JPG', f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function is from classify_image.py which creates graph from saved GraphDef file and returns a saver\n",
    "def create_graph():\n",
    "  \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n",
    "  # Creates graph from saved graph_def.pb.\n",
    "  with tf.gfile.FastGFile(os.path.join(\n",
    "      model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to generate bottleneck values from classifyimage.py\n",
    "def get_bottleneck_values(images):  # modifying name of function\n",
    "  \"\"\"Runs inference on an image.\n",
    "\n",
    "  Args:\n",
    "    image: Image file name.\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  # Creates graph from saved GraphDef.\n",
    "  create_graph()\n",
    "  feature_vector_size = 2048 # pool_3:0 contains a float description vector of size 2048  \n",
    "  with tf.Session() as sess:\n",
    "    # Some useful tensors:\n",
    "    # 'softmax:0': A tensor containing the normalized prediction across\n",
    "    #   1000 labels.\n",
    "    # 'pool_3:0': A tensor containing the next-to-last layer containing 2048\n",
    "    #   float description of the image.\n",
    "    # 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG\n",
    "    #   encoding of the image.\n",
    "    # Runs the softmax tensor by feeding the image_data as input to the graph.\n",
    "    bottleneck_tensor = sess.graph.get_tensor_by_name('pool_3:0') #changing from softmax:0 to pool_3:0\n",
    "    feature_vectors = np.empty([len(images),2048])\n",
    "    image_names = []\n",
    "    for i,image in enumerate(images): # Iterating through images \n",
    "        image_data = tf.gfile.FastGFile(image, 'rb').read()\n",
    "        feature_vector = sess.run(bottleneck_tensor,\n",
    "                           {'DecodeJpeg/contents:0': image_data})\n",
    "        feature_vector = np.squeeze(feature_vector)\n",
    "        image_names.append(image)\n",
    "        feature_vectors[i,:] = feature_vector \n",
    "        if(i % 10 == 0): #Print out just to see the function is processing \n",
    "            print(\"Processing image %d  %s\"%(i,image))\n",
    "    return feature_vectors,image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 0  ClothingAttributeDataset/images/000848.jpg\n",
      "Processing image 10  ClothingAttributeDataset/images/001335.jpg\n",
      "Processing image 20  ClothingAttributeDataset/images/000962.jpg\n",
      "Processing image 30  ClothingAttributeDataset/images/000127.jpg\n",
      "Processing image 40  ClothingAttributeDataset/images/000828.jpg\n",
      "Processing image 50  ClothingAttributeDataset/images/000939.jpg\n",
      "Processing image 60  ClothingAttributeDataset/images/000549.jpg\n",
      "Processing image 70  ClothingAttributeDataset/images/001625.jpg\n",
      "Processing image 80  ClothingAttributeDataset/images/001157.jpg\n",
      "Processing image 90  ClothingAttributeDataset/images/001500.jpg\n",
      "Processing image 100  ClothingAttributeDataset/images/001686.jpg\n",
      "Processing image 110  ClothingAttributeDataset/images/001195.jpg\n",
      "Processing image 120  ClothingAttributeDataset/images/001638.jpg\n",
      "Processing image 130  ClothingAttributeDataset/images/000545.jpg\n",
      "Processing image 140  ClothingAttributeDataset/images/001411.jpg\n",
      "Processing image 150  ClothingAttributeDataset/images/000548.jpg\n",
      "Processing image 160  ClothingAttributeDataset/images/000567.jpg\n",
      "Processing image 170  ClothingAttributeDataset/images/001448.jpg\n",
      "Processing image 180  ClothingAttributeDataset/images/000203.jpg\n",
      "Processing image 190  ClothingAttributeDataset/images/001853.jpg\n",
      "Processing image 200  ClothingAttributeDataset/images/000404.jpg\n",
      "Processing image 210  ClothingAttributeDataset/images/001121.jpg\n",
      "Processing image 220  ClothingAttributeDataset/images/001036.jpg\n",
      "Processing image 230  ClothingAttributeDataset/images/001131.jpg\n",
      "Processing image 240  ClothingAttributeDataset/images/001684.jpg\n",
      "Processing image 250  ClothingAttributeDataset/images/000898.jpg\n",
      "Processing image 260  ClothingAttributeDataset/images/000340.jpg\n",
      "Processing image 270  ClothingAttributeDataset/images/000224.jpg\n",
      "Processing image 280  ClothingAttributeDataset/images/001465.jpg\n",
      "Processing image 290  ClothingAttributeDataset/images/001295.jpg\n",
      "Processing image 300  ClothingAttributeDataset/images/000252.jpg\n",
      "Processing image 310  ClothingAttributeDataset/images/000804.jpg\n",
      "Processing image 320  ClothingAttributeDataset/images/000036.jpg\n",
      "Processing image 330  ClothingAttributeDataset/images/001347.jpg\n",
      "Processing image 340  ClothingAttributeDataset/images/001210.jpg\n",
      "Processing image 350  ClothingAttributeDataset/images/000787.jpg\n",
      "Processing image 360  ClothingAttributeDataset/images/001570.jpg\n",
      "Processing image 370  ClothingAttributeDataset/images/001491.jpg\n",
      "Processing image 380  ClothingAttributeDataset/images/000988.jpg\n",
      "Processing image 390  ClothingAttributeDataset/images/001331.jpg\n",
      "Processing image 400  ClothingAttributeDataset/images/001302.jpg\n",
      "Processing image 410  ClothingAttributeDataset/images/000274.jpg\n",
      "Processing image 420  ClothingAttributeDataset/images/001412.jpg\n",
      "Processing image 430  ClothingAttributeDataset/images/001023.jpg\n",
      "Processing image 440  ClothingAttributeDataset/images/000587.jpg\n",
      "Processing image 450  ClothingAttributeDataset/images/000996.jpg\n",
      "Processing image 460  ClothingAttributeDataset/images/000885.jpg\n",
      "Processing image 470  ClothingAttributeDataset/images/000995.jpg\n",
      "Processing image 480  ClothingAttributeDataset/images/000226.jpg\n",
      "Processing image 490  ClothingAttributeDataset/images/000209.jpg\n",
      "Processing image 500  ClothingAttributeDataset/images/000813.jpg\n",
      "Processing image 510  ClothingAttributeDataset/images/001378.jpg\n",
      "Processing image 520  ClothingAttributeDataset/images/001201.jpg\n",
      "Processing image 530  ClothingAttributeDataset/images/000137.jpg\n",
      "Processing image 540  ClothingAttributeDataset/images/001017.jpg\n",
      "Processing image 550  ClothingAttributeDataset/images/001382.jpg\n",
      "Processing image 560  ClothingAttributeDataset/images/000732.jpg\n",
      "Processing image 570  ClothingAttributeDataset/images/000510.jpg\n",
      "Processing image 580  ClothingAttributeDataset/images/001586.jpg\n",
      "Processing image 590  ClothingAttributeDataset/images/000115.jpg\n",
      "Processing image 600  ClothingAttributeDataset/images/001355.jpg\n",
      "Processing image 610  ClothingAttributeDataset/images/000605.jpg\n",
      "Processing image 620  ClothingAttributeDataset/images/001765.jpg\n",
      "Processing image 630  ClothingAttributeDataset/images/000601.jpg\n",
      "Processing image 640  ClothingAttributeDataset/images/001285.jpg\n",
      "Processing image 650  ClothingAttributeDataset/images/000835.jpg\n",
      "Processing image 660  ClothingAttributeDataset/images/000891.jpg\n",
      "Processing image 670  ClothingAttributeDataset/images/000126.jpg\n",
      "Processing image 680  ClothingAttributeDataset/images/001550.jpg\n",
      "Processing image 690  ClothingAttributeDataset/images/001110.jpg\n",
      "Processing image 700  ClothingAttributeDataset/images/000643.jpg\n",
      "Processing image 710  ClothingAttributeDataset/images/001176.jpg\n",
      "Processing image 720  ClothingAttributeDataset/images/001822.jpg\n",
      "Processing image 730  ClothingAttributeDataset/images/000583.jpg\n",
      "Processing image 740  ClothingAttributeDataset/images/000657.jpg\n",
      "Processing image 750  ClothingAttributeDataset/images/001467.jpg\n",
      "Processing image 760  ClothingAttributeDataset/images/000449.jpg\n",
      "Processing image 770  ClothingAttributeDataset/images/001660.jpg\n",
      "Processing image 780  ClothingAttributeDataset/images/001035.jpg\n",
      "Processing image 790  ClothingAttributeDataset/images/001171.jpg\n",
      "Processing image 800  ClothingAttributeDataset/images/000227.jpg\n",
      "Processing image 810  ClothingAttributeDataset/images/000350.jpg\n",
      "Processing image 820  ClothingAttributeDataset/images/001136.jpg\n",
      "Processing image 830  ClothingAttributeDataset/images/000521.jpg\n",
      "Processing image 840  ClothingAttributeDataset/images/001524.jpg\n",
      "Processing image 850  ClothingAttributeDataset/images/001404.jpg\n",
      "Processing image 860  ClothingAttributeDataset/images/000169.jpg\n",
      "Processing image 870  ClothingAttributeDataset/images/001462.jpg\n",
      "Processing image 880  ClothingAttributeDataset/images/000027.jpg\n",
      "Processing image 890  ClothingAttributeDataset/images/001664.jpg\n",
      "Processing image 900  ClothingAttributeDataset/images/001198.jpg\n",
      "Processing image 910  ClothingAttributeDataset/images/001103.jpg\n",
      "Processing image 920  ClothingAttributeDataset/images/000057.jpg\n",
      "Processing image 930  ClothingAttributeDataset/images/000528.jpg\n",
      "Processing image 940  ClothingAttributeDataset/images/001472.jpg\n",
      "Processing image 950  ClothingAttributeDataset/images/000425.jpg\n",
      "Processing image 960  ClothingAttributeDataset/images/000473.jpg\n",
      "Processing image 970  ClothingAttributeDataset/images/000721.jpg\n",
      "Processing image 980  ClothingAttributeDataset/images/001141.jpg\n",
      "Processing image 990  ClothingAttributeDataset/images/001299.jpg\n",
      "Processing image 1000  ClothingAttributeDataset/images/001216.jpg\n",
      "Processing image 1010  ClothingAttributeDataset/images/001193.jpg\n",
      "Processing image 1020  ClothingAttributeDataset/images/001369.jpg\n",
      "Processing image 1030  ClothingAttributeDataset/images/001219.jpg\n",
      "Processing image 1040  ClothingAttributeDataset/images/001795.jpg\n",
      "Processing image 1050  ClothingAttributeDataset/images/000129.jpg\n",
      "Processing image 1060  ClothingAttributeDataset/images/001282.jpg\n",
      "Processing image 1070  ClothingAttributeDataset/images/000319.jpg\n",
      "Processing image 1080  ClothingAttributeDataset/images/001424.jpg\n",
      "Processing image 1090  ClothingAttributeDataset/images/000277.jpg\n",
      "Processing image 1100  ClothingAttributeDataset/images/000541.jpg\n",
      "Processing image 1110  ClothingAttributeDataset/images/000910.jpg\n",
      "Processing image 1120  ClothingAttributeDataset/images/001650.jpg\n",
      "Processing image 1130  ClothingAttributeDataset/images/000358.jpg\n",
      "Processing image 1140  ClothingAttributeDataset/images/001566.jpg\n",
      "Processing image 1150  ClothingAttributeDataset/images/001102.jpg\n",
      "Processing image 1160  ClothingAttributeDataset/images/000144.jpg\n",
      "Processing image 1170  ClothingAttributeDataset/images/000067.jpg\n",
      "Processing image 1180  ClothingAttributeDataset/images/001174.jpg\n",
      "Processing image 1190  ClothingAttributeDataset/images/000538.jpg\n",
      "Processing image 1200  ClothingAttributeDataset/images/000830.jpg\n",
      "Processing image 1210  ClothingAttributeDataset/images/001245.jpg\n",
      "Processing image 1220  ClothingAttributeDataset/images/001676.jpg\n",
      "Processing image 1230  ClothingAttributeDataset/images/000428.jpg\n",
      "Processing image 1240  ClothingAttributeDataset/images/000524.jpg\n",
      "Processing image 1250  ClothingAttributeDataset/images/000793.jpg\n",
      "Processing image 1260  ClothingAttributeDataset/images/000747.jpg\n",
      "Processing image 1270  ClothingAttributeDataset/images/000592.jpg\n",
      "Processing image 1280  ClothingAttributeDataset/images/001006.jpg\n",
      "Processing image 1290  ClothingAttributeDataset/images/000330.jpg\n",
      "Processing image 1300  ClothingAttributeDataset/images/000849.jpg\n",
      "Processing image 1310  ClothingAttributeDataset/images/001200.jpg\n",
      "Processing image 1320  ClothingAttributeDataset/images/001253.jpg\n",
      "Processing image 1330  ClothingAttributeDataset/images/001052.jpg\n",
      "Processing image 1340  ClothingAttributeDataset/images/001257.jpg\n",
      "Processing image 1350  ClothingAttributeDataset/images/000040.jpg\n",
      "Processing image 1360  ClothingAttributeDataset/images/000020.jpg\n",
      "Processing image 1370  ClothingAttributeDataset/images/001633.jpg\n",
      "Processing image 1380  ClothingAttributeDataset/images/001818.jpg\n",
      "Processing image 1390  ClothingAttributeDataset/images/001772.jpg\n",
      "Processing image 1400  ClothingAttributeDataset/images/001804.jpg\n",
      "Processing image 1410  ClothingAttributeDataset/images/000259.jpg\n",
      "Processing image 1420  ClothingAttributeDataset/images/000507.jpg\n",
      "Processing image 1430  ClothingAttributeDataset/images/000936.jpg\n",
      "Processing image 1440  ClothingAttributeDataset/images/001286.jpg\n",
      "Processing image 1450  ClothingAttributeDataset/images/001637.jpg\n",
      "Processing image 1460  ClothingAttributeDataset/images/000348.jpg\n",
      "Processing image 1470  ClothingAttributeDataset/images/000124.jpg\n",
      "Processing image 1480  ClothingAttributeDataset/images/000050.jpg\n",
      "Processing image 1490  ClothingAttributeDataset/images/000497.jpg\n",
      "Processing image 1500  ClothingAttributeDataset/images/000913.jpg\n",
      "Processing image 1510  ClothingAttributeDataset/images/000065.jpg\n",
      "Processing image 1520  ClothingAttributeDataset/images/001405.jpg\n",
      "Processing image 1530  ClothingAttributeDataset/images/001741.jpg\n",
      "Processing image 1540  ClothingAttributeDataset/images/000978.jpg\n",
      "Processing image 1550  ClothingAttributeDataset/images/000644.jpg\n",
      "Processing image 1560  ClothingAttributeDataset/images/000310.jpg\n",
      "Processing image 1570  ClothingAttributeDataset/images/000537.jpg\n",
      "Processing image 1580  ClothingAttributeDataset/images/001831.jpg\n",
      "Processing image 1590  ClothingAttributeDataset/images/000630.jpg\n",
      "Processing image 1600  ClothingAttributeDataset/images/001641.jpg\n",
      "Processing image 1610  ClothingAttributeDataset/images/000559.jpg\n",
      "Processing image 1620  ClothingAttributeDataset/images/001133.jpg\n",
      "Processing image 1630  ClothingAttributeDataset/images/000054.jpg\n",
      "Processing image 1640  ClothingAttributeDataset/images/001798.jpg\n",
      "Processing image 1650  ClothingAttributeDataset/images/000812.jpg\n",
      "Processing image 1660  ClothingAttributeDataset/images/001527.jpg\n",
      "Processing image 1670  ClothingAttributeDataset/images/000923.jpg\n",
      "Processing image 1680  ClothingAttributeDataset/images/001791.jpg\n",
      "Processing image 1690  ClothingAttributeDataset/images/000833.jpg\n",
      "Processing image 1700  ClothingAttributeDataset/images/001614.jpg\n",
      "Processing image 1710  ClothingAttributeDataset/images/000158.jpg\n",
      "Processing image 1720  ClothingAttributeDataset/images/000247.jpg\n",
      "Processing image 1730  ClothingAttributeDataset/images/001170.jpg\n",
      "Processing image 1740  ClothingAttributeDataset/images/001438.jpg\n",
      "Processing image 1750  ClothingAttributeDataset/images/000745.jpg\n",
      "Processing image 1760  ClothingAttributeDataset/images/001283.jpg\n",
      "Processing image 1770  ClothingAttributeDataset/images/000351.jpg\n",
      "Processing image 1780  ClothingAttributeDataset/images/000173.jpg\n",
      "Processing image 1790  ClothingAttributeDataset/images/000068.jpg\n",
      "Processing image 1800  ClothingAttributeDataset/images/000468.jpg\n",
      "Processing image 1810  ClothingAttributeDataset/images/000039.jpg\n",
      "Processing image 1820  ClothingAttributeDataset/images/000026.jpg\n",
      "Processing image 1830  ClothingAttributeDataset/images/001522.jpg\n",
      "Processing image 1840  ClothingAttributeDataset/images/000604.jpg\n",
      "Processing image 1850  ClothingAttributeDataset/images/000602.jpg\n"
     ]
    }
   ],
   "source": [
    "attribute_features,image = get_bottleneck_values(training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_names = image\n",
    "feature_vectors_sorted = np.empty([len(training_images),2048])\n",
    "image_name_sorted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Since features are generated in random order data has to be sorted first. So that each row corresponds \n",
    "#to correct output in the attributes list.\n",
    "def sort():\n",
    "    k = 0\n",
    "    for i in range(1,1857):\n",
    "        num_string = str(i)\n",
    "        l = len(num_string)\n",
    "        num_string = (\"0\" * (6-l)) + num_string\n",
    "        for index, name in enumerate(image_names):\n",
    "            if re.search(num_string, name):\n",
    "                feature_vectors_sorted[k,:] = attribute_features[index,:]\n",
    "                image_name_sorted.append(image_names[index])\n",
    "                k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(feature_vectors_sorted,open('feature_vectors_sorted1','wb'))\n",
    "pickle.dump(image_name_sorted,open('image_names_sorted1','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
